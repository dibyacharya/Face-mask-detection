{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Set the `numpy` pseudo-random generator at a fixed value\n",
    "#This helps with repeatable results everytime you run the code. \n",
    "np.random.seed(1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import keras\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow' # Added to set the backend as Tensorflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import load_model\n",
    "from numpy import asarray\n",
    "from matplotlib import pyplot\n",
    "from numpy.random import randn\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 125, 125, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 60, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                802880    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 831,585\n",
      "Trainable params: 831,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "SIZE = 127\n",
    "INPUT_SHAPE = (SIZE, SIZE, 3)   #change to (SIZE, SIZE, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=45,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './New Masks Dataset/train',  # this is the input directory\n",
    "        target_size=(127, 127),  # all images will be resized to 64x64\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 306 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        './New Masks Dataset/validation',\n",
    "        target_size=(127, 127),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"saved_models/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\" #File name includes epoch and validation accuracy.\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4555 - accuracy: 0.8202\n",
      "Epoch 00001: val_accuracy improved from 0.90850 to 0.92763, saving model to saved_models\\weights-improvement-01-0.93.hdf5\n",
      "37/37 [==============================] - 22s 582ms/step - loss: 0.4555 - accuracy: 0.8202 - val_loss: 0.3090 - val_accuracy: 0.9276\n",
      "Epoch 2/5\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3679 - accuracy: 0.8647\n",
      "Epoch 00002: val_accuracy did not improve from 0.92763\n",
      "37/37 [==============================] - 20s 545ms/step - loss: 0.3679 - accuracy: 0.8647 - val_loss: 0.2878 - val_accuracy: 0.9013\n",
      "Epoch 3/5\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.8784\n",
      "Epoch 00003: val_accuracy did not improve from 0.92763\n",
      "37/37 [==============================] - 22s 586ms/step - loss: 0.3361 - accuracy: 0.8784 - val_loss: 0.3824 - val_accuracy: 0.8520\n",
      "Epoch 4/5\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.8938\n",
      "Epoch 00004: val_accuracy did not improve from 0.92763\n",
      "37/37 [==============================] - 21s 574ms/step - loss: 0.3170 - accuracy: 0.8938 - val_loss: 0.2558 - val_accuracy: 0.8947\n",
      "Epoch 5/5\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.8921\n",
      "Epoch 00005: val_accuracy did not improve from 0.92763\n",
      "37/37 [==============================] - 20s 545ms/step - loss: 0.2926 - accuracy: 0.8921 - val_loss: 0.2337 - val_accuracy: 0.9145\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=600 // batch_size,    #The 2 slashes division return rounded integer\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=306 // batch_size,\n",
    "        callbacks=callbacks_list)\n",
    "model.save('facemask_augmented_model.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-22e66cee4728>:5: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      " validation loss and accuracy are [0.24001377820968628, 0.9117646813392639]\n",
      "Epoch 1/5\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.9007\n",
      "Epoch 00001: val_accuracy did not improve from 0.92763\n",
      "37/37 [==============================] - 18s 478ms/step - loss: 0.2691 - accuracy: 0.9007 - val_loss: 0.2967 - val_accuracy: 0.8980\n",
      "Epoch 2/5\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.9058\n",
      "Epoch 00002: val_accuracy did not improve from 0.92763\n",
      "37/37 [==============================] - 18s 476ms/step - loss: 0.2584 - accuracy: 0.9058 - val_loss: 0.3848 - val_accuracy: 0.8882\n",
      "Epoch 3/5\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.9092\n",
      "Epoch 00003: val_accuracy did not improve from 0.92763\n",
      "37/37 [==============================] - 21s 562ms/step - loss: 0.2740 - accuracy: 0.9092 - val_loss: 0.2736 - val_accuracy: 0.8914\n",
      "Epoch 4/5\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2530 - accuracy: 0.9092\n",
      "Epoch 00004: val_accuracy did not improve from 0.92763\n",
      "37/37 [==============================] - 19s 527ms/step - loss: 0.2530 - accuracy: 0.9092 - val_loss: 0.2682 - val_accuracy: 0.9046\n",
      "Epoch 5/5\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.9144\n",
      "Epoch 00005: val_accuracy did not improve from 0.92763\n",
      "37/37 [==============================] - 19s 504ms/step - loss: 0.2444 - accuracy: 0.9144 - val_loss: 0.2543 - val_accuracy: 0.9079\n"
     ]
    }
   ],
   "source": [
    "#To continue training, by modifying weights to existing model.\n",
    "#The saved model can be reinstated.\n",
    "from keras.models import load_model\n",
    "new_model = load_model('facemask_augmented_model.h5')\n",
    "results = new_model.evaluate_generator(validation_generator)\n",
    "print(\" validation loss and accuracy are\", results)\n",
    "new_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=600 // batch_size,    #The 2 slashes division return rounded integer\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=306 // batch_size,\n",
    "        callbacks=callbacks_list)\n",
    "model.save('facemask_augmented_model_updated.h5') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = load_img('./New Masks Dataset/test/Mask/2086.jpg', target_size = (127, 127))\n",
    "img2 = load_img('./New Masks Dataset/test/Non Mask/real_01066.jpg', target_size = (127, 127))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = img_to_array(img1)\n",
    "x2 = img_to_array(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.reshape((1,) + x1.shape)\n",
    "x2 = x2.reshape((1,) + x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = model.predict(x1)\n",
    "x2 = model.predict(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n"
     ]
    }
   ],
   "source": [
    "#training_set.class_indices\n",
    "if x1==0:\n",
    "    prediction = 'mask'\n",
    "    print(prediction)\n",
    "else :\n",
    "    prediction = 'unmask'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unmask\n"
     ]
    }
   ],
   "source": [
    "if x2==0:\n",
    "    prediction = 'mask'\n",
    "    print(prediction)\n",
    "else :\n",
    "    prediction = 'unmask'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
